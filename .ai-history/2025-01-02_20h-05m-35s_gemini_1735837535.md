  -- When "body_chunks" is about 160 items, the curl POST request fails with a "Too many open files" error.
  -- Analyze the for loop below and tell me where it generate a lot of open files.
  for i, message in ipairs(body_chunks) do
    local body = vim.fn.json_encode(message)
    curl.post(url,
      {
        headers = {['Content-type'] = 'application/json'},
        body = body,
        callback = function(res)
          if i == #body_chunks then
            vim.schedule(function() query.askCallback(res, opts) end)
          end
        end
      })
  end



# This is gemini-2.0-flash-thinking-exp answer (342k in, 0k out)

The issue lies in the fact that `curl.post` is asynchronous and you are rapidly firing off many requests within the loop *before* getting responses back. Each `curl.post` call can open a file descriptor (or equivalent resource) for the network connection, and if you make enough requests quickly, you can exhaust the available file descriptors.  The callback function you provide to `curl.post` is executed later, *after* the request has completed, not immediately.

The loop doesn't wait for each `curl.post` to finish before starting the next one. So, if `body_chunks` is large, you'll initiate many simultaneous connections, leading to the "Too many open files" error.

Here's how to fix it using a recursive approach to ensure only one request runs at a time:

```lua
local curl = require('plenary.curl')
local aiconfig = require('ai.aiconfig')
local common = require('ai.common')
local query = {}
local history = require('ai.history')

local promptToSave = ""
local modelUsed = ""

-- ... (other functions)

function query.askHeavy(model, instruction, prompt, opts, agent_host)
  promptToSave = prompt
  modelUsed = model
  local url = agent_host .. '/chatgpt'
  local project_context = aiconfig.listScannedFilesFromConfig()
  local body_chunks = {}
  table.insert(body_chunks, {system_instruction = instruction})
  table.insert(body_chunks, {role = 'user', content = "I need your help on this project."})
  table.insert(body_chunks, {role = 'model', content = "Tell me the project file structure."})
  table.insert(body_chunks, {role = 'user',  content = aiconfig.listScannedFilesAsText()})
  for _, context in pairs(project_context) do
    if aiconfig.contentOf(context) ~= nil then
      table.insert(body_chunks, {role = 'model', content = "What is the content of `" .. context .. "` ?"})
      table.insert(body_chunks, {role = 'user',  content = "The content of `" .. context .. "` is :\n```\n" .. aiconfig.contentOf(context) .. "\n```"})
    end
  end
  table.insert(body_chunks, {role = 'model', content = "Then what do you want me to do with all that information?"})
  table.insert(body_chunks, {role = 'user', content = prompt})
  table.insert(body_chunks, {model_to_use = model})
  table.insert(body_chunks, {temperature = 0.2})
  table.insert(body_chunks, {top_p = 0.1})
  table.insert(body_chunks, {})


  local function sendNextRequest(i)
    if i > #body_chunks then
      return -- All requests sent
    end

    local message = body_chunks[i]
    local body = vim.fn.json_encode(message)

    curl.post(url,
      {
        headers = {['Content-type'] = 'application/json'},
        body = body,
        callback = function(res)
          if i == #body_chunks then
            vim.schedule(function() query.askCallback(res, opts) end)
          else
            sendNextRequest(i + 1) -- Send the next request after the current one completes
          end
        end
      })
  end

  sendNextRequest(1) -- Start the chain of requests
end


-- ... (rest of the file)
```

By using `sendNextRequest` recursively,  a new request is sent only *after* the previous one has completed and its callback has been executed. This prevents the accumulation of open file descriptors and resolves the "Too many open files" error.
