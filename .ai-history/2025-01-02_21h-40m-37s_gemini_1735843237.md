# Vimscript function must not be called in a lua loop callback 

When launching a command defined in "code-ai.nvim", I get the following error:

```
Error executing luv callback:
lua/ai/chatgpt/query.lua:59: E5560: Vimscript function must not be called in a lua loop callback
stack traceback:
        [C]: in function 'json_encode'
        ...al/share/nvim/lazy/code-ai.nvim/lua/ai/chatgpt/query.lua:59: in function 'sendNextRequest'
        ...al/share/nvim/lazy/code-ai.nvim/lua/ai/chatgpt/query.lua:69: in function '_user_on_exit'
        .../.local/share/nvim/lazy/plenary.nvim/lua/plenary/job.lua:241: in function '_shutdown'
```

I made the `sendNextRequest` construction in order to wait for the response from the API before sending the next request.
This is in order to avoid having too much file descriptors open at the same time.
This feature needs to stay, but I need to find a way to fix this error.

Analyze the code in `./lua/ai/chatgpt/query.lua` and tell me what is wrong, then how should I manage it.



# This is gemini-2.0-flash-thinking-exp answer (8k in, 1k out)

The error message "Vimscript function must not be called in a lua loop callback" arises because you're calling `vim.fn.json_encode` within the `callback` function of `curl.post`.  This callback is executed by the libuv event loop, and calling Vimscript functions (anything using `vim.fn`) from within this loop is prohibited due to threading limitations.

Here's the corrected version of `lua/ai/chatgpt/query.lua`:

```lua
local curl = require('plenary.curl')
local aiconfig = require('ai.aiconfig')
local common = require('ai.common')
local query = {}
local history = require('ai.history')

local promptToSave = ""
local modelUsed = ""

function query.formatResult(data)
  common.log("Inside ChatGPT formatResult")
  local prompt_tokens = data.usage.prompt_tokens
  local completion_tokens = data.usage.completion_tokens

  local formatted_prompt_tokens = string.format("%%%%gk", math.floor(prompt_tokens / 1000))
  local formatted_completion_tokens = string.format("%%%%gk", math.floor(completion_tokens / 1000))

  local result = '\n# This is '.. modelUsed .. ' answer (' .. formatted_prompt_tokens .. ' in, ' .. formatted_completion_tokens .. ' out)\n\n'
  result = result .. data.choices[1].message.content .. '\n\n'
  history.saveToHistory('chatgpt', promptToSave .. '\n\n' .. common.escapePercent(result))
  return common.escapePercent(result)
end

query.askCallback = function(res, opts)
  common.askCallback(res, opts, query.formatResult)
end

function query.askHeavy(model, instruction, prompt, opts, agent_host)
  promptToSave = prompt
  modelUsed = model
  local url = agent_host .. '/chatgpt'
  local project_context = aiconfig.listScannedFilesFromConfig()
  local body_chunks = {}
  table.insert(body_chunks, {system_instruction = instruction})
  table.insert(body_chunks, {role = 'user', content = "I need your help on this project."})
  table.insert(body_chunks, {role = 'model', content = "Tell me the project file structure."})
  table.insert(body_chunks, {role = 'user',  content = aiconfig.listScannedFilesAsText()})
  for _, context in pairs(project_context) do
    if aiconfig.contentOf(context) ~= nil then
      table.insert(body_chunks, {role = 'model', content = "What is the content of `" .. context .. "` ?"})
      table.insert(body_chunks, {role = 'user',  content = "The content of `" .. context .. "` is :\n```\n" .. aiconfig.contentOf(context) .. "\n```"})
    end
  end
  table.insert(body_chunks, {role = 'model', content = "Then what do you want me to do with all that information?"})
  table.insert(body_chunks, {role = 'user', content = prompt})
  table.insert(body_chunks, {model_to_use = model})
  table.insert(body_chunks, {temperature = 0.2})
  table.insert(body_chunks, {top_p = 0.1})
  table.insert(body_chunks, {})

  local function sendNextRequest(i)
    if i > #body_chunks then
      return -- All requests sent
    end

    local message = body_chunks[i]
    -- Encode the body *before* entering the callback
    local body = vim.json.encode(message)

    curl.post(url,
      {
        headers = {['Content-type'] = 'application/json'},
        body = body,
        callback = function(res)
          if i == #body_chunks then
            -- Schedule the callback to run outside the libuv loop.
            vim.schedule(function() query.askCallback(res, opts) end)
          else
            sendNextRequest(i + 1)
          end
        end
      })
  end

  sendNextRequest(1)
end

-- ... (rest of the file remains unchanged)
```

Key changes:

1. **Pre-encode JSON:** The `vim.json.encode(message)` call is moved *outside* the `curl.post` callback and into the `sendNextRequest` function. This ensures the encoding happens in the main thread, not the libuv loop.  Note the use of  `vim.json.encode` which is the Lua implementation, not the Vimscript one (`vim.fn.json_encode`).

2. **Schedule `query.askCallback`:**  While you were already scheduling `query.askCallback`, it's crucial that *all* Vimscript interactions are scheduled. Since `query.askCallback` internally uses functions from `common.lua` which might interact with Vim, it's safest to schedule it.


By making these changes, you avoid calling Vimscript functions from within the libuv callback, resolving the error.  The chain of requests is preserved, and the file descriptor issue is mitigated.
