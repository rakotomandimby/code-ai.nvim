# Code review

Review the code and tell me what is to improve in order to make it easy for human to read it.



# This is claude-opus-4-20250514 answer (14k in, 8k out)

After reviewing the code, here are the main improvements I recommend to make it more human-readable:

## 1. **Add Module Documentation**

Each file should have a header comment explaining its purpose. Here's an improved version of `lua/ai/init.lua`:

```lua
--- AI plugin for Neovim - Main module
--- This plugin provides integration with multiple AI providers (Anthropic, Google AI, OpenAI)
--- to assist with code analysis and generation tasks.
---
--- @module ai
--- @author Your Name
--- @license MIT

local anthropic = require('ai.anthropic.query')
local googleai = require('ai.googleai.query')
local openai = require('ai.openai.query')
local aiconfig = require('ai.aiconfig')
local common = require('ai.common')

-- Default prompt configurations
local default_prompts = {
  introduce = {
    command = 'AIIntroduceYourself',
    loading_tpl = 'Loading...',
    prompt_tpl = 'Say who you are, your version, and the currently used model',
    result_tpl = '${output}',
    require_input = false,
  }
}

local M = {}

--- Plugin configuration options
--- @field anthropic_model string The Anthropic model to use (e.g., "claude-3-opus")
--- @field googleai_model string The Google AI model to use (e.g., "gemini-pro")
--- @field openai_model string The OpenAI model to use (e.g., "gpt-4")
--- @field anthropic_agent_host string URL of the Anthropic agent server (optional)
--- @field googleai_agent_host string URL of the Google AI agent server (optional)
--- @field openai_agent_host string URL of the OpenAI agent server (optional)
--- @field anthropic_api_key string API key for Anthropic
--- @field googleai_api_key string API key for Google AI
--- @field openai_api_key string API key for OpenAI
--- @field locale string Primary locale for responses (default: 'en')
--- @field alternate_locale string Secondary locale for responses (default: 'fr')
--- @field result_popup_gets_focus boolean Whether the result popup should receive focus
M.opts = {
  anthropic_model = '',
  googleai_model = '',
  openai_model = '',

  anthropic_agent_host = '',
  googleai_agent_host = '',
  openai_agent_host = '',

  anthropic_api_key = '',
  googleai_api_key = '',
  openai_api_key = '',

  locale = 'en',
  alternate_locale = 'fr',
  result_popup_gets_focus = false,
}

M.prompts = default_prompts
local win_id

--- Split a string into lines
--- @param input string The input string to split
--- @return table Array of lines
local function splitLines(input)
  local lines = {}
  local offset = 1
  while offset > 0 do
    local i = string.find(input, '\n', offset)
    if i == nil then
      table.insert(lines, string.sub(input, offset, -1))
      offset = 0
    else
      table.insert(lines, string.sub(input, offset, i - 1))
      offset = i + 1
    end
  end
  return lines
end

--- Join lines into a single string
--- @param lines table Array of lines to join
--- @return string The joined string with newlines
local function joinLines(lines)
  local result = ""
  for _, line in ipairs(lines) do
    result = result .. line .. "\n"
  end
  return result
end

--- Check if a string is empty or nil
--- @param text string|nil The text to check
--- @return boolean True if text is nil or empty
local function isEmpty(text)
  return text == nil or text == ''
end

--- Check if text contains letters
--- @param text any The text to check
--- @return boolean True if text contains letters
function M.hasLetters(text)
  return type(text) == 'string' and text:match('[a-zA-Z]') ~= nil
end

--- Get the currently selected text in visual mode
--- @param esc boolean Whether to escape visual mode first
--- @return string The selected text
function M.getSelectedText(esc)
  if esc then
    vim.api.nvim_feedkeys(vim.api.nvim_replace_termcodes('<esc>', true, false, true), 'n', false)
  end
  local vstart = vim.fn.getpos("'<")
  local vend = vim.fn.getpos("'>")
  local ok, lines = pcall(vim.api.nvim_buf_get_text, 0, vstart[2] - 1, vstart[3] - 1, vend[2] - 1, vend[3], {})
  if ok then
    return joinLines(lines)
  else
    lines = vim.api.nvim_buf_get_lines(0, vstart[2] - 1, vend[2], false)
    return joinLines(lines)
  end
end

--- Close the popup window if it exists
function M.close()
  if win_id == nil or win_id == vim.api.nvim_get_current_win() then
    return
  end
  pcall(vim.api.nvim_win_close, win_id, true)
  win_id = nil
end

--- Create a popup window with initial content
--- @param initialContent string Initial content to display
--- @param width number Window width
--- @param height number Window height
--- @return function Update function to modify popup content
function M.createPopup(initialContent, width, height)
  M.close()
  local bufnr = vim.api.nvim_create_buf(false, true)

  local update = function(content)
    if content == nil then
      content = ''
    end
    local lines = splitLines(content)
    vim.bo[bufnr].modifiable = true
    vim.api.nvim_buf_set_lines(bufnr, 0, -1, true, lines)
    vim.bo[bufnr].modifiable = false
  end

  win_id = vim.api.nvim_open_win(bufnr, false, {
    relative = 'cursor',
    border = 'single',
    title = 'code-ai.md',
    style = 'minimal',
    width = width,
    height = height,
    row = 1,
    col = 0,
  })
  vim.api.nvim_buf_set_option(bufnr, 'filetype', 'markdown')
  vim.api.nvim_buf_set_option(bufnr, 'wrap', true)
  update(initialContent)
  if M.opts.result_popup_gets_focus then
    vim.api.nvim_set_current_win(win_id)
  end
  return update
end

--- Fill a template string with variables
--- @param tpl string|nil Template string with ${variable} placeholders
--- @param args table Table of variable names to values
--- @return string The filled template
function M.fill(tpl, args)
  if tpl == nil then
    tpl = ''
  else
    for key, value in pairs(args) do
      tpl = string.gsub(tpl, '%${' .. key .. '}', value)
    end
  end
  return tpl
end

--- Handle a prompt command
--- @param name string The prompt name from M.prompts
--- @param input string The input text
function M.handle(name, input)
  local def = M.prompts[name]
  local width = vim.fn.winwidth(0)
  local height = vim.fn.winheight(0)
  local args = {
    locale = M.opts.locale,
    alternate_locale = M.opts.alternate_locale,
    input = input,
    input_encoded = vim.fn.json_encode(input),
  }

  local number_of_files = #aiconfig.listScannedFilesFromConfig()
  local use_anthropic_agent = M.opts.anthropic_agent_host ~= ''
  local use_googleai_agent = M.opts.googleai_agent_host ~= ''
  local use_openai_agent = M.opts.openai_agent_host ~= ''

  local update = nil

  -- Show loading popup with file list if using agents
  if (number_of_files == 0 or not use_anthropic_agent or not use_googleai_agent or not use_openai_agent ) then
    update = M.createPopup(M.fill(def.loading_tpl , args), width - 8, height - 4)
  else
    local scanned_files = aiconfig.listScannedFilesAsFormattedTable()
    update = M.createPopup(M.fill(def.loading_tpl .. scanned_files, args), width - 8, height - 4)
  end
  
  local prompt = M.fill(def.prompt_tpl, args)
  -- Get system instructions from file or fall back to command definition
  local instruction = aiconfig.getSystemInstructions()

  -- Determine which models to use (command-specific or global)
  local anthropic_model = def.anthropic_model or M.opts.anthropic_model
  local googleai_model = def.googleai_model or M.opts.googleai_model
  local openai_model = def.openai_model or M.opts.openai_model

  -- Override with command-level models if specified
  if def.anthropic_model and def.anthropic_model ~= '' then
    anthropic_model = def.anthropic_model
  end
  if def.googleai_model and def.googleai_model ~= '' then
    googleai_model = def.googleai_model
  end
  if def.openai_model and def.openai_model ~= '' then
    openai_model = def.openai_model
  end

  --- Handle result from AI provider
  --- @param output string The AI response
  --- @param output_key string The key to store the output under
  local function handleResult(output, output_key)
    args[output_key] = output
    args.output = (args.anthropic_output or '').. (args.googleai_output or '') .. (args.openai_output or '')
    update(M.fill(def.result_tpl or '${output}', args))
  end

  -- Create callback handlers for each AI provider
  local askHandleResultAndCallbackAnthropic = {
    handleResult = function(output) return handleResult(output, 'anthropic_output') end,
    callback = function() end
  }

  local askHandleResultAndCallbackGoogleAI = {
    handleResult = function(output) return handleResult(output, 'googleai_output') end,
    callback = function() end
  }

  local askHandleResultAndCallbackOpenAI = {
    handleResult = function(output) return handleResult(output, 'openai_output') end,
    callback = function() end
  }

  -- Decide whether to use heavy (agent-based) or light (direct API) queries
  if (number_of_files == 0
        or not use_anthropic_agent
        or not use_googleai_agent
        or not use_openai_agent) then
    common.log("Not using agents")
    anthropic.askLight(
      anthropic_model,
      instruction,
      prompt,
      askHandleResultAndCallbackAnthropic,
      M.opts.anthropic_api_key)
    googleai.askLight(
      googleai_model,
      instruction,
      prompt,
      askHandleResultAndCallbackGoogleAI,
      M.opts.googleai_api_key)
    openai.askLight(
      openai_model,
      instruction,
      prompt,
      askHandleResultAndCallbackOpenAI,
      M.opts.openai_api_key)
  else
    common.log("Using agents")
    anthropic.askHeavy(
      anthropic_model,
      instruction,
      prompt,
      askHandleResultAndCallbackAnthropic,
      M.opts.anthropic_agent_host)
    googleai.askHeavy(
      googleai_model,
      instruction,
      prompt,
      askHandleResultAndCallbackGoogleAI,
      M.opts.googleai_agent_host)
    openai.askHeavy(
      openai_model,
      instruction,
      prompt,
      askHandleResultAndCallbackOpenAI,
      M.opts.openai_agent_host)
  end
end

--- Merge tables, overwriting values in the first table
--- @param table table Target table
--- @param other table Source table
--- @return table The modified target table
function M.assign(table, other)
  for k, v in pairs(other) do
    table[k] = v
  end
  return table
end

--- Setup the plugin with user configuration
--- @param opts table User configuration options
function M.setup(opts)
  -- Merge user options with defaults
  for k, v in pairs(opts) do
    if k == 'prompts' then
      M.prompts = {}
      M.assign(M.prompts, default_prompts)
      M.assign(M.prompts, v)
    elseif M.opts[k] ~= nil then
      M.opts[k] = v
    end
  end
  
  -- Create user commands for each prompt
  for k, v in pairs(M.prompts) do
    if v.command then
      vim.api.nvim_create_user_command(v.command, function(args)
        local text = args['args']
        if isEmpty(text) then
          text = M.getSelectedText(true)
        end
        if not v.require_input or M.hasLetters(text) then
          M.handle(k, text)
        end
      end, { range = true, nargs = '?' })
    end
  end

  -- Validate required configuration
  if M.opts.anthropic_model == '' or  M.opts.googleai_model == '' or M.opts.openai_model == '' then
    error('You need to set both anthropic_model and googleai_model and openai_model')
  end
  if M.opts.anthropic_api_key ==''or M.opts.googleai_api_key == '' or M.opts.openai_api_key == '' then
    error('You need to set both anthropic_api_key and googleai_api_key and openai_api_key')
  end

  -- Create utility commands
  vim.api.nvim_create_user_command('AIListScannedFiles', function()
    local width = vim.fn.winwidth(0)
    local height = vim.fn.winheight(0)
    local scanned_files = aiconfig.listScannedFilesAsFormattedTable()
    local update = M.createPopup(scanned_files, width - 12, height - 8)
    update(scanned_files)
  end, {})

  vim.api.nvim_create_user_command('AIShowSystemInstructions', function()
    local width = vim.fn.winwidth(0)
    local height = vim.fn.winheight(0)
    local instructions = aiconfig.getSystemInstructions()
    local update = M.createPopup(instructions, width - 12, height - 8)
    update(instructions)
  end, {})
end

-- Auto-close popup when cursor moves
vim.api.nvim_create_autocmd({ 'CursorMoved', 'CursorMovedI' }, {
  callback = M.close,
})

return M
```

## 2. **Improve `aiconfig.lua` Organization**

Here's an improved version with better structure and documentation:

```lua
--- AI Configuration Module
--- Handles project configuration, file scanning, and system instructions
---
--- @module aiconfig

local aiconfig = {}
local common = require("ai.common")
local globpattern = require("ai.globpattern")

-- ===========================================================================
-- System Instructions Management
-- ===========================================================================

--- Find the system instructions file in the current working directory
--- @return string Path to the file if found, empty string otherwise
function aiconfig.findSystemInstructionsFile()
  local path = vim.fn.getcwd() .. '/.ai-system-instructions.md'
  local file = io.open(path, "r")
  if file ~= nil then
    io.close(file)
    return path
  else
    return ""
  end
end

--- Get the content of the system instructions file
--- @return string Content of the file or empty string if not found
function aiconfig.getSystemInstructions()
  local path = aiconfig.findSystemInstructionsFile()
  if path == "" then
    return ""
  end

  local file = io.open(path, "r")
  if not file then
    return ""
  end

  local content = file:read("*all")
  file:close()
  return content
end

-- ===========================================================================
-- Project Configuration
-- ===========================================================================

--- Find the scanned files configuration
--- @return string Path to the config file if found, empty string otherwise
function aiconfig.findScannedFilesConfig()
  local path = vim.fn.getcwd() .. '/.ai-scanned-files'
  local file = io.open(path, "r")
  if file ~= nil then
    io.close(file)
    return path
  else
    return ""
  end
end

--- Determine the project root directory
--- Searches for project markers in this order:
--- 1. .ai-scanned-files
--- 2. .git directory
--- 3. .gitignore file
--- 4. README.md file
--- @return string The project root directory path
function aiconfig.getProjectRoot()
  local project_root = vim.fn.getcwd() -- Start with the current working directory
  
  -- Check for .ai-scanned-files
  local configFile = aiconfig.findScannedFilesConfig()
  if configFile ~= "" then
    project_root = vim.fn.fnamemodify(configFile, ":h")
    return project_root
  end

  -- Check for .git directory
  local gitDir = vim.fn.finddir(".git", ".;")
  if gitDir ~= "" then
    project_root = vim.fn.fnamemodify(gitDir, ":h")
    return project_root
  end

  -- Check for .gitignore file
  local gitignoreFile = vim.fn.findfile(".gitignore", ".;")
  if gitignoreFile ~= "" then
    project_root = vim.fn.fnamemodify(gitignoreFile, ":h")
    return project_root
  end

  -- Check for README.md file
  local readmeFile = vim.fn.findfile("README.md", ".;")
  if readmeFile ~= "" then
    project_root = vim.fn.fnamemodify(readmeFile, ":h")
    return project_root
  end
  
  return project_root
end

-- ===========================================================================
-- File Scanning
-- ===========================================================================

--- List files to scan based on .ai-scanned-files configuration
--- The config file format:
--- - Lines starting with '+' are include patterns
--- - Lines starting with '-' are exclude patterns
--- - Empty lines and single character lines are ignored
--- @return table Array of relative file paths sorted by size (largest first)
function aiconfig.listScannedFilesFromConfig()
  local config = aiconfig.findScannedFilesConfig()
  if config == "" then
    common.log("No .ai-scanned-files config found.")
    return {}
  end

  local include_glob_patterns = {}
  local exclude_glob_patterns = {}

  -- Parse configuration file
  common.log("Reading scanned files config: " .. config)
  for line in io.lines(config) do
    local trimmed_line = vim.trim(line)
    if #trimmed_line > 1 then -- Ignore empty or single character lines
        if vim.startswith(trimmed_line, "+") then
          local pattern = trimmed_line:sub(2)
          table.insert(include_glob_patterns, pattern)
          common.log("Include glob pattern: " .. pattern)
        elseif vim.startswith(trimmed_line, "-") then
          local pattern = trimmed_line:sub(2)
          table.insert(exclude_glob_patterns, pattern)
          common.log("Exclude glob pattern: " .. pattern)
        end
    end
  end

  -- Convert exclude patterns to Lua patterns for efficiency
  local exclude_lua_patterns = {}
  for _, pattern in ipairs(exclude_glob_patterns) do
    local lua_pattern = globpattern.globtopattern(pattern)
    table.insert(exclude_lua_patterns, lua_pattern)
    common.log("Converted exclude glob '" .. pattern .. "' to Lua pattern: " .. lua_pattern)
  end

  local files_with_sizes = {}
  local processed_files = {} -- Track processed files to avoid duplicates
  local project_root = aiconfig.getProjectRoot()

  -- Process each include pattern
  for _, include_pattern in ipairs(include_glob_patterns) do
    common.log("Processing include glob pattern: " .. include_pattern)
    -- Find files matching the include pattern
    local potential_files = vim.fn.glob(project_root .. '/' .. include_pattern, false, true)

    for _, full_path in ipairs(potential_files) do
      -- Make path relative to project root
      local relative_path = string.sub(full_path, #project_root + 2) -- +2 for the '/' and 1-based index

      -- Skip if already processed
      if not processed_files[relative_path] then
        local is_excluded = false
        
        -- Check against exclude patterns
        for _, exclude_pattern in ipairs(exclude_lua_patterns) do
          if string.match(relative_path, exclude_pattern) then
            is_excluded = true
            common.log("File '" .. relative_path .. "' excluded by pattern: " .. exclude_pattern)
            break
          end
        end

        -- Add file if not excluded
        if not is_excluded then
          local file_info = vim.loop.fs_stat(full_path)
          -- Ensure it's a file (not a directory)
          if file_info and file_info.type == 'file' then
            table.insert(files_with_sizes, {
              path = relative_path,
              size = file_info.size
            })
            processed_files[relative_path] = true
            common.log("File '" .. relative_path .. "' included (Size: " .. file_info.size .. ")")
          else
             common.log("Path '" .. relative_path .. "' is not a file or stat failed, skipping.")
          end
        end
      else
        common.log("File '" .. relative_path .. "' already processed, skipping duplicate.")
      end
    end
  end

  -- Sort by size (largest first)
  table.sort(files_with_sizes, function(a, b)
    return a.size > b.size
  end)

  -- Extract just the paths
  local final_files = {}
  for _, file_data in ipairs(files_with_sizes) do
    table.insert(final_files, file_data.path)
  end

  common.log("Total included files after filtering and sorting: " .. #final_files)
  return final_files
end

--- Generate a human-readable sentence listing scanned files
--- @return string A sentence describing the project files
function aiconfig.listScannedFilesAsSentence()
  local analyzed_files_as_array = aiconfig.listScannedFilesFromConfig()
  local num_files = #analyzed_files_as_array

  if num_files == 0 then
    return ""
  end

  local file_names = {}
  for _, file in ipairs(analyzed_files_as_array) do
    table.insert(file_names, string.format("`%s`", file))
  end

  local analyzed_files_as_string = "The project is composed of " .. num_files .. " file" .. (num_files > 1 and "s" or "") .. ": "

  if num_files == 1 then
    analyzed_files_as_string = analyzed_files_as_string .. file_names[1] .. "."
  elseif num_files == 2 then
    analyzed_files_as_string = analyzed_files_as_string .. table.concat(file_names, " and ") .. "."
  else
    analyzed_files_as_string = analyzed_files_as_string .. table.concat(file_names, ", ", 1, num_files - 1) .. ", and " .. file_names[num_files] .. "."
  end

  return analyzed_files_as_string
end

--- Read the content of a file from the project
--- @param file string Relative path to the file
--- @return string File content or empty string if read fails
function aiconfig.contentOf(file)
  -- Construct full path from project root and relative path
  local full_path = aiconfig.getProjectRoot() .. '/' .. file
  local f = io.open(full_path, "r")
  if f then
    local filecontent = f:read("*all")
    f:close()
    return filecontent
  end
  common.log("Could not read content of: " .. full_path)
  return ""
end

-- ===========================================================================
-- Formatting Utilities
-- ===========================================================================

--- Format file size in human-readable format
--- @param size number Size in bytes
--- @return string Formatted size (e.g., "1.5 MB", "42 KB", "100 B")
local function format_size(size)
  if size > 1024 * 1024 then
    return string.format("%.2f MB", size / (1024 * 1024))
  elseif size > 1024 then
    return string.format("%.2f KB", size / 1024)
  else
    return size .. " B"
  end
end

--- Generate a formatted Markdown table of scanned files
--- Shows files sorted by size and by name in two columns
--- @return string Markdown-formatted table
function aiconfig.listScannedFilesAsFormattedTable()
  local analyzed_files_paths = aiconfig.listScannedFilesFromConfig()
  local project_root = aiconfig.getProjectRoot()

  if #analyzed_files_paths == 0 then
    return "# No files to analyze under project root " .. project_root
  end

  local files_data = {}
  local total_size = 0
  local max_display_length = 0 -- Tracks the max length of the combined "path (size)" string

  -- Pass 1: Gather file data and calculate maximum display string length
  common.log("Starting Pass 1: Gathering file data and calculating max display length")
  for _, relative_path in ipairs(analyzed_files_paths) do
    local full_path = project_root .. '/' .. relative_path
    local stat = vim.loop.fs_stat(full_path)
    local size = stat and stat.size or 0
    total_size = total_size + size
    local size_str = format_size(size)
    -- Create the display string for the table cell
    local display_str = relative_path .. " (" .. size_str .. ")"

    -- Track the maximum length needed for any cell content
    max_display_length = math.max(max_display_length, #display_str)

    table.insert(files_data, {
      path = relative_path,
      size = size,
      size_str = size_str,
      display_str = display_str
    })
    common.log("Processed: " .. display_str .. " (Length: " .. #display_str .. ")")
  end
  common.log("Pass 1 Complete. Max display length: " .. max_display_length)

  -- files_data is already sorted by size (from listScannedFilesFromConfig)
  local sorted_by_size = files_data

  -- Create a copy sorted by name
  local sorted_by_name = {}
  for _, data in ipairs(files_data) do
    table.insert(sorted_by_name, data)
  end
  table.sort(sorted_by_name, function(a, b)
    return a.path < b.path
  end)

  -- Format total size
  local total_size_str = format_size(total_size)

  -- Pass 2: Build the Markdown table
  common.log("Starting Pass 2: Building Markdown table")
  local result_lines = {}
  table.insert(result_lines, "# A total of " .. total_size_str .. " will be analyzed under project root " .. project_root .. ":\n")

  -- Define headers
  local header1 = "Sorted by Size (Desc)"
  local header2 = "Sorted by Name (Asc)"

  -- Calculate column widths based on headers and content
  local col1_width = math.max(#header1, max_display_length)
  local col2_width = math.max(#header2, max_display_length)
  common.log("Calculated column widths: Col1=" .. col1_width .. ", Col2=" .. col2_width)

  --- Helper function to pad strings to a fixed width (left-aligned)
  local function pad_right(str, width)
    return str .. string.rep(" ", width - #str)
  end

  -- Add header row
  table.insert(result_lines, "| " .. pad_right(header1, col1_width) .. " | " .. pad_right(header2, col2_width) .. " |")

  -- Add separator line
  table.insert(result_lines, "|-" .. string.rep("-", col1_width) .. "-|-" .. string.rep("-", col2_width) .. "-|")

  -- Add data rows
  for i = 1, #sorted_by_size do
    -- Get the pre-calculated display strings
    local display_size = sorted_by_size[i].display_str
    local display_name = sorted_by_name[i].display_str

    -- Pad to column widths
    local padded_display_size = pad_right(display_size, col1_width)
    local padded_display_name = pad_right(display_name, col2_width)

    table.insert(result_lines, "| " .. padded_display_size .. " | " .. padded_display_name .. " |")
  end
  common.log("Pass 2 Complete. Table built.")

  return table.concat(result_lines, "\n")
end

return aiconfig
```

## 3. **Improve Query Modules Structure**

Here's an improved version of `lua/ai/anthropic/query.lua` (similar improvements should be applied to googleai and openai):

```lua
--- Anthropic Claude API Query Module
--- Handles communication with Anthropic's Claude models
---
--- @module anthropic.query

local curl = require('plenary.curl')
local aiconfig = require('ai.aiconfig')
local common = require('ai.common')
local history = require('ai.history')

local query = {}

-- Module-level variables to track current request
local promptToSave = ""
local modelUsed = ""

-- Constants
local API_HOST = 'https://api.anthropic.com'
local API_VERSION = '2023-06-01'
local MAX_TOKENS = 8192
local TEMPERATURE = 0.2
local TOP_P = 0.1

-- Response for disabled models
local DISABLED_RESPONSE = {
  content = { { text = "Anthropic models are disabled" } },
  usage = { input_tokens = 0, output_tokens = 0 }
}

--- Format token count for display
--- @param tokens number Token count
--- @return string Formatted string (e.g., "1.5k")
local function formatTokens(tokens)
  return string.format("%gk", math.floor(tokens / 1000))
end

--- Format the API response for display
--- @param data table The API response data
--- @return string Formatted markdown string
function query.formatResult(data)
  common.log("Inside Anthropic formatResult")
  
  local input_tokens = data.usage.input_tokens or 0
  local output_tokens = data.usage.output_tokens or 0

  local formatted_input_tokens = formatTokens(input_tokens)
  local formatted_output_tokens = formatTokens(output_tokens)

  -- Create the result string with token counts
  local result = string.format(
    '\n# This is %s answer (%s in, %s out)\n\n%s\n\n',
    modelUsed,
    formatted_input_tokens,
    formatted_output_tokens,
    data.content

