# Feature addition: Upload LLM answers to a location.

I want to upload the displayed answers generated by the LLM to a specific location, such as a blog or a file storage service. 
The uploaded content will be the part that is displayed in the UI, which is not the raw response from the LLM but rather the formatted text that is shown to the final user.

Tehcnical details:

- Method: `PUT`
- Mandatory header and value: "Content-Type: text/markdown"   
- Mandatory header "X-MardkdownBlog-Token", and take the value from the configuration parameter named `upload_token`   
- Upload URL: take it from the configuration parameter named `upload_url`
- Body: the raw response from the LLM

I do not want to LLMs responses to be modified merged, I want them to be uploaded separately, one upload per response. 

Tell me the modifications I need to make to the code to implement this feature.




# This is disabled answer (0k in, 0k out)

Anthropic models are disabled

