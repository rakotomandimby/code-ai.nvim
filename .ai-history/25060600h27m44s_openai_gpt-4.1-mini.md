# Do not upload to "upload_url" if the model is "disabled"

When the model is "disabled", I would like to avoid to upload the LLM answer to the "upload_url" field.

Tell me how to do that.


# This is gpt-4.1-mini answer (13k in, 1k out)

To avoid uploading the LLM answer when the model is `"disabled"`, you need to modify the `formatResult` functions in each of the LLM query modules (`anthropic/query.lua`, `googleai/query.lua`, and `openai/query.lua`) so that they skip calling `common.uploadContent` if the model is `"disabled"`.

### How to do it:

In each `formatResult` function, add a check before calling `common.uploadContent` like this:

```lua
if modelUsed ~= "disabled" then
  common.uploadContent(upload_url, upload_token, result, 'ModelName (' .. modelUsed .. ')')
end
```

Replace `'ModelName'` with the appropriate model name (`Anthropic`, `GoogleAI`, or `OpenAI`).

---

### Example for `lua/ai/anthropic/query.lua`:

Modify the `formatResult` function as follows:

```lua
function query.formatResult(data, upload_url, upload_token)
  common.log("Inside Anthropic formatResult")
  local input_tokens = data.usage.input_tokens or 0
  local output_tokens = data.usage.output_tokens or 0

  local formatted_input_tokens = string.format("%gk", math.floor(input_tokens / 1000))
  local formatted_output_tokens = string.format("%gk", math.floor(output_tokens / 1000))

  local result = '# This is '.. modelUsed .. ' answer (' .. formatted_input_tokens .. ' in, ' .. formatted_output_tokens .. ' out)\n\n'
  result = result .. data.content[1].text .. '\n\n'
  history.saveToHistory('claude_' .. modelUsed , promptToSave .. '\n\n' .. result)

  -- Only upload if model is not "disabled"
  if modelUsed ~= "disabled" then
    common.uploadContent(upload_url, upload_token, result, 'Anthropic (' .. modelUsed .. ')')
  end

  return result
end
```

---

### Similarly for `lua/ai/googleai/query.lua`:

```lua
function query.formatResult(data, upload_url, upload_token)
  common.log("Inside GoogleAI formatResult")
  local result = ''
  local candidates_number = #data['candidates']
  if candidates_number == 1 then
    if data['candidates'][1]['content'] == nil then
      result = '\n#GoogleAI error\n\nGoogleAI stopped with the reason: ' .. data['candidates'][1]['finishReason'] .. '\n'
      return result
    else
      local prompt_tokens = data['usageMetadata']['promptTokenCount'] or 0
      local answer_tokens = data['usageMetadata']['candidatesTokenCount'] or 0

      local formatted_prompt_tokens = string.format("%gk", math.floor(prompt_tokens / 1000))
      local formatted_answer_tokens = string.format("%gk", math.floor(answer_tokens / 1000))

      result = '# This is ' .. modelUsed .. ' answer (' .. formatted_prompt_tokens .. ' in, ' .. formatted_answer_tokens .. ' out)\n\n'
      result = result .. data['candidates'][1]['content']['parts'][1]['text'] .. '\n'
    end
  else
    result = '# There are ' .. candidates_number .. ' GoogleAI candidates\n'
    for i = 1, candidates_number do
      result = result .. '## GoogleAI Candidate number ' .. i .. '\n'
      result = result .. data['candidates'][i]['content']['parts'][1]['text'] .. '\n'
    end
  end
  history.saveToHistory('googleai_' .. modelUsed  , promptToSave .. '\n\n' .. result)

  if modelUsed ~= "disabled" then
    common.uploadContent(upload_url, upload_token, result, 'GoogleAI (' .. modelUsed .. ')')
  end

  return result
end
```

---

### And for `lua/ai/openai/query.lua`:

```lua
function query.formatResult(data, upload_url, upload_token)
  common.log("Inside OpenAI formatResult")
  local prompt_tokens = data.usage.prompt_tokens or 0
  local completion_tokens = data.usage.completion_tokens or 0

  local formatted_prompt_tokens = string.format("%gk", math.floor(prompt_tokens / 1000))
  local formatted_completion_tokens = string.format("%gk", math.floor(completion_tokens / 1000))

  local result = '# This is '.. modelUsed .. ' answer (' .. formatted_prompt_tokens .. ' in, ' .. formatted_completion_tokens .. ' out)\n\n'
  result = result .. data.choices[1].message.content .. '\n\n'
  history.saveToHistory('openai_' .. modelUsed , promptToSave .. '\n\n' .. result)

  if modelUsed ~= "disabled" then
    common.uploadContent(upload_url, upload_token, result, 'OpenAI (' .. modelUsed .. ')')
  end

  return result
end
```

---

### Summary

- Add a conditional check `if modelUsed ~= "disabled"` before calling `common.uploadContent` in each `formatResult` function.
- This prevents uploading when the model is `"disabled"`.

This is the cleanest and most localized way to prevent uploads for disabled models without changing the rest of the code flow.

