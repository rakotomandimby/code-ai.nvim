# New README.md content after adding `append_embeded_system_instructions`

I just added a new configuration option `append_embeded_system_instructions` to control whether the plugin should append the embedded system instructions to the user provided ones before sending them to the AI model.

Give me the full new content of the README.md file, including the new documentation about this configuration option.

If you notice some missing documentation, please add it as well.



# ANT Update README.md with documentation for the new `append_embeded_system_instructions` configuration option

We need to update the README.md file to document the new `append_embeded_system_instructions` configuration option that controls whether the plugin appends embedded system instructions to user-provided ones. We'll also add any missing documentation we notice while reviewing the current content.

## README.md

```markdown
# Acknowledgements

I would like first to thank [gera2ld](https://github.com/gera2ld) for his work on [ai.nvim](https://github.com/gera2ld/ai.nvim), because this plugin is a fork of his work. 
Without his plugin, there wouldnt be this one.
Thank you Gerald for your work.

# code-ai.nvim

A Neovim plugin powered by GoogleAI Gemini, OpenAI ChatGPT and Anthropic Claude to help you write code.

Here is a demo without using the agents:

[![Demonstration](https://img.youtube.com/vi/fkVt4ozc-w8/0.jpg)](https://www.youtube.com/watch?v=fkVt4ozc-w8)

Here is a demo using the agents:

[![Demonstration](https://img.youtube.com/vi/Mmv7dKrak7Q/0.jpg)](https://www.youtube.com/watch?v=Mmv7dKrak7Q)

# How it works

- The plugin resides in Neovim.
- If the agents URLs are defined, it will send the prompt to the agent, which will send it to the corresponding LLM API.
  - It scans the files corresponding to the patterns defined in [.ai-scanned-files](./.ai-scanned-files) and builds a multi-turn chat from them.
  - It sends the [multi-turn chat and the prompt](./documentation/multi-turn-chat.json) to the agents
  - It receives the response from the agents and displays it in a popup
- If the agent URL are not defined, it will send the prompt directly to the corresponding LLM API.
  - It **does not scan** any files
  - It **does not build a multi-turn chat** but directly sends the prompt to the LLM API
  - It receives the response from the agents and displays it in a popup

# The agent

You can find the agent in the repository [code-ai-agent](https://github.com/rakotomandimby/code-ai-agent).

## Installation

First get API keys from 
- [Google Cloud](https://ai.google.dev/gemini-api/docs/api-key) 
- [ChatGPT](https://platform.openai.com/api-keys)
- [Anthropic](https://console.anthropic.com/settings/keys)

For usage **WITHOUT** the agents, **don't set** the `googleai_agent_host` nor `openai_agent_host` nor `anthropic_agent_host`.

For usage **WITH** the agents, **set** the `googleai_agent_host` and `openai_agent_host` and `anthropic_agent_host` to the URLs of the agents.

This is the configuration for the plugin:

```lua
{
    'rakotomandimby/code-ai.nvim',
    dependencies = 'nvim-lua/plenary.nvim',
    opts = {
        anthropic_model = 'claude-3-7-sonnet-latest',
        googeai_model   = 'gemini-2.0-flash-exp',
        openai_model    = 'gpt-4o-mini',

        anthropic_api_key = 'YOUR_ANTHROPIC_API_KEY',      -- or read from env: `os.getenv('ANTHROPIC_API_KEY')`
        googleai_api_key  = 'YOUR_GOOGLEAI_API_KEY',       -- or read from env: `os.getenv('GOOGLEAI_API_KEY')`
        openai_api_key    = 'YOUR_OPENAI_API_KEY',         -- or read from env: `os.getenv('OPENAI_API_KEY')`

        anthropic_agent_host = 'http://172.16.76.1:6000',    -- dont set if you dont want to use the agent
                                                             -- if you set, make sure the agents are running
        googleai_agent_host  = 'http://172.16.76.1:5000',    -- dont set if you dont want to use the agent
                                                             -- if you set, make sure the agents are running
        openai_agent_host    = 'http://172.16.76.1:4000',    -- dont set if you dont want to use the agent
                                                             -- if you set, make sure the agents are running
        
        result_popup_gets_focus = true,
        locale = 'en',
        alternate_locale = 'fr',
        
        -- System instructions configuration
        append_embeded_system_instructions = true,           -- Whether to append embedded system instructions to user-provided ones (default: true)
        
        -- Upload configuration (optional)
        upload_url = '',                                     -- URL to upload AI responses (leave empty to disable)
        upload_token = '',                                   -- Authentication token for upload service
        upload_as_public = false,                            -- Whether to make uploaded content public (default: false)
        
        -- Define custom prompts here, see below for more details
        prompts = {
            javascript_vanilla = {
                command = 'AIJavascriptVanilla',
                prompt_tpl = '${input}',
                result_tpl = '${output}',
                loading_tpl = 'Loading...',
                require_input = true,
                anthropic_model='claude-3-7-sonnet-latest',
                googleai_model='gemini-2.0-flash-exp',
                openai_model='gpt-4o-mini',
            },
            php_bare = {
                command = 'AIPhpBare',
                prompt_tpl = '${input}',
                result_tpl = '${output}',
                loading_tpl = 'Loading...',
                require_input = true,
                anthropic_model='claude-3-7-sonnet-latest',
                googleai_model='gemini-2.0-flash-exp',
                openai_model='gpt-4o-mini',
            },
        },
    },
    event = 'VimEnter',
},
```

## Usage

If you have configured the plugin following the instructions above, you can use the plugin by:
- Selecting a text in normal mode
- Pressing `:` to enter the command mode
- Typing `AIJavascriptVanilla` or `AIPhpBare` and pressing `Enter`

## Built-in Commands

The plugin provides several built-in commands:

- `:AIIntroduceYourself` - Ask the AI models to introduce themselves and show their versions
- `:AIListScannedFiles` - Show a formatted table of files that will be analyzed based on your `.ai-scanned-files` configuration
- `:AIShowSystemInstructions` - Display the complete system instructions that will be sent to the AI models

## System Instructions

The plugin uses system instructions to provide context to the AI models. There are two types of system instructions:

1. **User System Instructions**: Create a `.ai-system-instructions.md` file in your project root to provide custom instructions specific to your project.

2. **Embedded System Instructions**: The plugin includes built-in system instructions (`lua/ai/common-system-instructions.md`) that provide general guidance to the AI models.

The `append_embeded_system_instructions` configuration option controls whether the embedded system instructions are appended to your user-provided instructions:
- `true` (default): Both user and embedded instructions are sent to the AI
- `false`: Only user instructions are sent (embedded instructions are skipped)

This can be overridden on a per-prompt basis by setting `append_embeded_system_instructions` in individual prompt configurations.

## File Scanning Configuration

Create a `.ai-scanned-files` file in your project root to specify which files should be analyzed when using agents. The format is:

- Lines starting with `+` specify include patterns (glob patterns)
- Lines starting with `-` specify exclude patterns (glob patterns)

Example `.ai-scanned-files`:
```
+*.lua
+*.md
+*.json
-node_modules/**
-*.log
-/.git/**
```

## Configuration Reference

The prompts will be merged into built-in prompts. Here are the available fields for each prompt:

### Global Configuration Options

| Field                               | Required | Default | Description                                                                                        |
| ----------------------------------- | -------- | ------- | -------------------------------------------------------------------------------------------------- |
| `googleai_model`                    | Yes      | -       | The model to use for the GoogleAI Gemini API. Set it to 'disabled' if you don't want to use it.  |
| `openai_model`                      | Yes      | -       | The model to use for the OpenAI ChatGPT API. Set it to 'disabled' if you don't want to use it.   |
| `anthropic_model`                   | Yes      | -       | The model to use for the Anthropic Claude API. Set it to 'disabled' if you don't want to use it. |
| `googleai_api_key`                  | Yes      | -       | The API key for the GoogleAI Gemini API.                                                         |
| `openai_api_key`                    | Yes      | -       | The API key for the OpenAI ChatGPT API.                                                          |
| `anthropic_api_key`                 | Yes      | -       | The API key for the Anthropic Claude API.                                                        |
| `googleai_agent_host`               | No       | ''      | The host of the GoogleAI Gemini agent.                                                           |
| `openai_agent_host`                 | No       | ''      | The host of the OpenAI ChatGPT agent.                                                            |
| `anthropic_agent_host`              | No       | ''      | The host of the Anthropic Claude agent.                                                          |
| `locale`                            | No       | 'en'    | Primary locale for AI responses.                                                                  |
| `alternate_locale`                  | No       | 'fr'    | Alternative locale for AI responses.                                                              |
| `result_popup_gets_focus`           | No       | false   | Whether the result popup window should receive focus when opened.                                 |
| `append_embeded_system_instructions`| No       | true    | Whether to append embedded system instructions to user-provided ones.                            |
| `upload_url`                        | No       | ''      | URL to upload AI responses. Leave empty to disable upload functionality.                         |
| `upload_token`                      | No       | ''      | Authentication token for the upload service.                                                     |
| `upload_as_public`                  | No       | false   | Whether to make uploaded content publicly accessible.                                            |

### Per-Prompt Configuration Options

| Field                               | Required | Description                                                                                        |
| ----------------------------------- | -------- | -------------------------------------------------------------------------------------------------- |
| `command`                           | Yes      | A user command will be created for this prompt.                                                   |
| `loading_tpl`                       | No       | Template for content shown when communicating with AI models. See below for available placeholders. |
| `prompt_tpl`                        | Yes      | Template for the prompt string passed to AI models. See below for available placeholders.        |
| `result_tpl`                        | No       | Template for the result shown in the popup. See below for available placeholders.                |
| `require_input`                     | No       | If set to `true`, the prompt will only be sent if text is selected or passed to the command.     |
| `anthropic_model`                   | No       | Override the global Anthropic model for this specific prompt.                                     |
| `googleai_model`                    | No       | Override the global GoogleAI model for this specific prompt.                                      |
| `openai_model`                      | No       | Override the global OpenAI model for this specific prompt.                                        |
| `append_embeded_system_instructions`| No       | Override the global setting for appending embedded system instructions for this specific prompt. |

### Template Placeholders

Placeholders can be used in templates. If not available, they will be left as-is.

| Placeholder         | Description                                                                                | Availability      |
| ------------------- | ------------------------------------------------------------------------------------------ | ----------------- |
| `${locale}`         | The configured primary locale (`opts.locale`).                                            | Always            |
| `${alternate_locale}`| The configured alternative locale (`opts.alternate_locale`).                             | Always            |
| `${input}`          | The text selected or passed to the command.                                               | Always            |
| `${input_encoded}`  | The selected text JSON-encoded for safe inclusion in templates.                           | Always            |
| `${output}`         | The combined result returned by all enabled AI models.                                    | After the request |
| `${anthropic_output}`| The result returned specifically by the Anthropic model.                                 | After the request |
| `${googleai_output}` | The result returned specifically by the GoogleAI model.                                  | After the request |
| `${openai_output}`  | The result returned specifically by the OpenAI model.                                     | After the request |

## Upload Functionality

The plugin can automatically upload AI responses to a configured endpoint. This is useful for sharing results or keeping a record of AI interactions. Configure the upload functionality with:

- `upload_url`: The endpoint URL where responses should be uploaded
- `upload_token`: Authentication token for the upload service
- `upload_as_public`: Whether uploaded content should be publicly accessible

If `upload_url` or `upload_token` are empty, upload functionality is disabled.

## History

The plugin automatically saves all AI interactions to a `.ai-history` directory in your project root. History files are named with timestamps and model information, and the plugin automatically removes old history files to keep only the 15 most recent interactions.
```

Anthropic claude-sonnet-4-20250514 (20k in, 3k out)


