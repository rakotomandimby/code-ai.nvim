# Scope of `append_embeded_system_instructions`

I just added a new configuration option `append_embeded_system_instructions` to control whether the plugin should append the embedded system instructions to the user provided ones before sending them to the AI model.

I dont know if this is a global setting or a command-level setting.

Help me to figure it out.


# ANT Analyze the scope of `append_embeded_system_instructions` configuration option

I need to analyze the current implementation to determine whether `append_embeded_system_instructions` is intended as a global setting, command-level setting, or both, and clarify how it should work.

Looking at the current implementation, I can see that the `append_embeded_system_instructions` option is implemented with **both global and command-level scope**, similar to how model selection works in the plugin.

## Current Implementation Analysis

In `lua/ai/init.lua`, the logic shows:

```lua
local append_embeded = M.opts.append_embeded_system_instructions
if def.append_embeded_system_instructions ~= nil then
  append_embeded = def.append_embeded_system_instructions
end
```

This follows the same pattern as the model configuration, where:
1. **Global default**: `M.opts.append_embeded_system_instructions = true` (set in the default options)
2. **Command-level override**: Each prompt definition can override this with its own `append_embeded_system_instructions` setting

## How It Works

1. **Global Setting**: The plugin defaults to `append_embeded_system_instructions = true` in `M.opts`
2. **Command-Level Override**: Individual prompts can override this by setting `append_embeded_system_instructions` in their prompt definition
3. **Precedence**: Command-level settings take precedence over global settings

## Example Usage

```lua
-- In your plugin setup
require('ai').setup({
  append_embeded_system_instructions = false, -- Global default: don't append
  prompts = {
    my_custom_prompt = {
      command = 'MyCustomCommand',
      prompt_tpl = 'Do something specific',
      append_embeded_system_instructions = true, -- Override: do append for this command
    },
    another_prompt = {
      command = 'AnotherCommand', 
      prompt_tpl = 'Do something else',
      -- Will use global setting (false in this example)
    }
  }
})
```

## Conclusion

The implementation is **correctly designed as both a global and command-level setting**. This provides maximum flexibility:

- **Global scope**: Set a default behavior for all commands
- **Command-level scope**: Override the global setting for specific commands that need different behavior
- **Backward compatibility**: Defaults to `true` to maintain existing behavior

This design pattern is consistent with how other configuration options like `anthropic_model`, `googleai_model`, and `openai_model` work in the plugin, making it intuitive for users who are already familiar with the plugin's configuration system.

Anthropic claude-sonnet-4-20250514 (18k in, 0k out)


